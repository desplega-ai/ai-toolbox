# API Command Implementation Plan

## Overview

Add an `api` command to hn-sql that starts a FastAPI server enabling remote SQL execution and REST-like endpoints for querying Hacker News data. The API returns query results along with execution timing information.

## Current State Analysis

- **CLI Framework**: Click-based CLI with commands: `fetch`, `stats`, `reset`, `query` (`cli.py:24-532`)
- **Query execution**: `_get_connection()` creates in-memory DuckDB with `hn` view (`cli.py:384-391`)
- **Timing**: Uses `time.perf_counter()` with `_format_time()` helper (`cli.py:370-381`)
- **Dependencies**: httpx, pyarrow, rich, click, duckdb, pytz (`pyproject.toml:7-14`)

### Key Discoveries:
- DuckDB connection is stateless - each query creates fresh connection (`cli.py:384-391`)
- Result handling extracts columns from `result.description`, rows from `result.fetchall()` (`cli.py:394-414`)
- Data path is configurable via `--data` option, defaults to `data/items/**/*.parquet` (`cli.py:21`)

## Desired End State

A working `api` command that:
1. Starts a FastAPI server on a configurable port (default 8000)
2. Provides POST `/query` endpoint for arbitrary SQL execution
3. Provides REST endpoints for common queries: `/stories`, `/comments`, `/jobs`
4. Provides analytics endpoints: `/stats/types`, `/stats/users`, `/top/stories`
5. Returns JSON with query results and timing information
6. Enforces a default 1,000 row limit (configurable per request)

### Verification:
```bash
# Start the API server
uv run hn-sql api --port 8080

# Test SQL execution
curl -X POST http://localhost:8080/query \
  -H "Content-Type: application/json" \
  -d '{"sql": "SELECT type, count(*) as cnt FROM hn GROUP BY type"}'

# Test REST endpoint
curl "http://localhost:8080/stories?limit=10&sort=score"

# Test analytics
curl http://localhost:8080/stats/types
```

## What We're NOT Doing

- Authentication/authorization (local tool)
- Rate limiting
- Persistent connections or connection pooling
- WebSocket/streaming responses
- Query caching
- OpenAPI documentation hosting (auto-generated by FastAPI is sufficient)

## Implementation Approach

1. Add FastAPI and uvicorn as dependencies
2. Create new `api.py` module with Pydantic models and endpoints
3. Add `api` command to CLI that starts uvicorn server
4. Reuse existing `_get_connection()` and `_format_time()` functions

---

## Phase 1: Add FastAPI Dependencies

### Overview
Add FastAPI and uvicorn to project dependencies.

### Changes Required:

#### 1. Update pyproject.toml
**File**: `pyproject.toml`
**Changes**: Add fastapi and uvicorn dependencies

```toml
dependencies = [
    "httpx>=0.28.0",
    "pyarrow>=18.0.0",
    "rich>=13.0.0",
    "click>=8.1.0",
    "duckdb>=1.4.2",
    "pytz>=2025.2",
    "fastapi>=0.115.0",
    "uvicorn>=0.32.0",
]
```

### Success Criteria:

#### Automated Verification:
- [x] Dependencies install: `uv sync`
- [x] FastAPI importable: `uv run python -c "import fastapi; print(fastapi.__version__)"`
- [x] Uvicorn importable: `uv run python -c "import uvicorn; print(uvicorn.__version__)"`

#### Manual Verification:
- [ ] No dependency conflicts

**Implementation Note**: After completing this phase and all automated verification passes, proceed to the next phase.

---

## Phase 2: Create API Module with Response Models

### Overview
Create the API module with Pydantic models for request/response schemas.

### Changes Required:

#### 1. Create API module
**File**: `src/hn_sql/api.py`
**Changes**: New file with FastAPI app, Pydantic models, and helper functions

```python
"""FastAPI server for hn-sql queries."""

import time
from typing import Any

import duckdb
from fastapi import FastAPI, HTTPException, Query
from pydantic import BaseModel, Field

# Default configuration
DEFAULT_LIMIT = 1000
MAX_LIMIT = 10000
DATA_PATH = "data/items/**/*.parquet"

app = FastAPI(
    title="HN-SQL API",
    description="Query Hacker News data with SQL",
    version="0.1.0",
)


# --- Response Models ---

class TimingInfo(BaseModel):
    """Execution timing information."""
    elapsed_seconds: float = Field(..., description="Query execution time in seconds")
    elapsed_formatted: str = Field(..., description="Human-readable execution time")


class QueryRequest(BaseModel):
    """SQL query request."""
    sql: str = Field(..., description="SQL query to execute", min_length=1)
    limit: int = Field(DEFAULT_LIMIT, description="Maximum rows to return", ge=1, le=MAX_LIMIT)


class QueryResponse(BaseModel):
    """SQL query response."""
    columns: list[str] = Field(..., description="Column names")
    rows: list[list[Any]] = Field(..., description="Result rows")
    row_count: int = Field(..., description="Number of rows returned")
    truncated: bool = Field(..., description="Whether results were truncated by limit")
    timing: TimingInfo


class StoryItem(BaseModel):
    """Story item for REST endpoints."""
    id: int
    title: str | None
    url: str | None
    score: int | None
    by: str | None
    time: str | None
    descendants: int | None


class CommentItem(BaseModel):
    """Comment item for REST endpoints."""
    id: int
    text: str | None
    by: str | None
    time: str | None
    parent: int | None


class JobItem(BaseModel):
    """Job item for REST endpoints."""
    id: int
    title: str | None
    url: str | None
    text: str | None
    by: str | None
    time: str | None


class TypeCount(BaseModel):
    """Type count for stats."""
    type: str
    count: int


class UserCount(BaseModel):
    """User post count for stats."""
    user: str
    count: int


class ListResponse(BaseModel):
    """Generic list response with timing."""
    items: list[Any]
    count: int
    timing: TimingInfo


class StatsResponse(BaseModel):
    """Stats response with timing."""
    stats: list[Any]
    timing: TimingInfo


# --- Helper Functions ---

def _format_time(seconds: float) -> str:
    """Format execution time in a human-readable way."""
    if seconds < 0.001:
        return f"{seconds * 1_000_000:.0f}Âµs"
    elif seconds < 1:
        return f"{seconds * 1000:.1f}ms"
    elif seconds < 60:
        return f"{seconds:.2f}s"
    else:
        mins = int(seconds // 60)
        secs = seconds % 60
        return f"{mins}m {secs:.1f}s"


def _get_connection(data_path: str = DATA_PATH) -> duckdb.DuckDBPyConnection:
    """Create a DuckDB connection with the HN data as a view."""
    conn = duckdb.connect()
    conn.execute(f"""
        CREATE VIEW hn AS
        SELECT * FROM read_parquet('{data_path}', hive_partitioning=true)
    """)
    return conn


def _execute_query(sql: str, limit: int = DEFAULT_LIMIT) -> QueryResponse:
    """Execute SQL and return structured response with timing."""
    conn = _get_connection()

    start_time = time.perf_counter()
    try:
        result = conn.execute(sql)
        columns = [col[0] for col in result.description]
        all_rows = result.fetchall()
    except duckdb.Error as e:
        raise HTTPException(status_code=400, detail=str(e))
    finally:
        conn.close()

    elapsed = time.perf_counter() - start_time

    # Apply limit
    truncated = len(all_rows) > limit
    rows = all_rows[:limit]

    # Convert rows to lists (from tuples)
    rows_as_lists = [list(row) for row in rows]

    return QueryResponse(
        columns=columns,
        rows=rows_as_lists,
        row_count=len(rows_as_lists),
        truncated=truncated,
        timing=TimingInfo(
            elapsed_seconds=elapsed,
            elapsed_formatted=_format_time(elapsed),
        ),
    )
```

### Success Criteria:

#### Automated Verification:
- [x] Module imports: `uv run python -c "from hn_sql.api import app, QueryRequest, QueryResponse"`
- [x] Models validate correctly: `uv run python -c "from hn_sql.api import QueryRequest; r = QueryRequest(sql='SELECT 1'); print(r.sql)"`

#### Manual Verification:
- [ ] Pydantic models have appropriate field descriptions

**Implementation Note**: After completing this phase and all automated verification passes, proceed to the next phase.

---

## Phase 3: Implement POST /query Endpoint

### Overview
Add the core SQL execution endpoint.

### Changes Required:

#### 1. Add query endpoint to api.py
**File**: `src/hn_sql/api.py`
**Changes**: Add POST /query endpoint

```python
# Add to api.py after helper functions

@app.post("/query", response_model=QueryResponse)
async def execute_query(request: QueryRequest) -> QueryResponse:
    """
    Execute a SQL query against the HN data.

    The data is available as a table called `hn` with columns:
    id, type, "by", time, text, url, title, score, descendants,
    parent, kids, dead, deleted, poll, parts, year, month

    Note: "by" must be quoted as it's a reserved word.
    """
    return _execute_query(request.sql, request.limit)


@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {"status": "ok"}
```

### Success Criteria:

#### Automated Verification:
- [x] Endpoint exists: `uv run python -c "from hn_sql.api import app; print([r.path for r in app.routes])"`

#### Manual Verification:
- [ ] OpenAPI docs show endpoint correctly at /docs

**Implementation Note**: After completing this phase and all automated verification passes, proceed to the next phase.

---

## Phase 4: Add API CLI Command

### Overview
Add the `api` command to CLI that starts the uvicorn server.

### Changes Required:

#### 1. Add api command to cli.py
**File**: `src/hn_sql/cli.py`
**Changes**: Add new `api` command after the `query` command

```python
# Add import at top of file (around line 9)
# No new imports needed - uvicorn will be imported inside the function

# Add command after query command (around line 465)

@main.command()
@click.option("--port", "-p", default=8000, help="Port to run the API server on")
@click.option("--host", "-h", default="127.0.0.1", help="Host to bind the server to")
@click.option("--reload", "-r", is_flag=True, help="Enable auto-reload for development")
@click.option("--data", "-d", default=DATA_PATH, help="Path to parquet files")
def api(port: int, host: str, reload: bool, data: str):
    """Start the FastAPI server for remote SQL execution.

    Examples:

      # Start on default port 8000
      hn-sql api

      # Start on custom port
      hn-sql api --port 8080

      # Allow external connections
      hn-sql api --host 0.0.0.0

      # Development mode with auto-reload
      hn-sql api --reload
    """
    import uvicorn
    from pathlib import Path

    # Check data exists
    data_dir = Path(data).parent.parent if "**" in data else Path(data).parent
    if not data_dir.exists() or not list(data_dir.glob("**/*.parquet")):
        console.print("[yellow]No data found. Run 'hn-sql fetch' first.[/yellow]")
        return

    # Update the data path in the API module
    from hn_sql import api as api_module
    api_module.DATA_PATH = data

    console.print(f"[bold green]Starting HN-SQL API server[/bold green]")
    console.print(f"  Host: {host}")
    console.print(f"  Port: {port}")
    console.print(f"  Data: {data}")
    console.print(f"  Docs: http://{host}:{port}/docs")
    console.print()

    uvicorn.run(
        "hn_sql.api:app",
        host=host,
        port=port,
        reload=reload,
    )
```

### Success Criteria:

#### Automated Verification:
- [x] Command exists: `uv run hn-sql api --help`
- [x] Help shows port option
- [x] Help shows host option

#### Manual Verification:
- [ ] Server starts correctly: `uv run hn-sql api` (then Ctrl+C to stop)
- [ ] API responds: `curl http://localhost:8000/health`

**Implementation Note**: After completing this phase and all automated verification passes, pause here for manual confirmation that the server starts and responds before proceeding to the next phase.

---

## Phase 5: Implement REST Entity Endpoints

### Overview
Add REST-like GET endpoints for stories, comments, and jobs.

### Changes Required:

#### 1. Add entity endpoints to api.py
**File**: `src/hn_sql/api.py`
**Changes**: Add GET endpoints for /stories, /comments, /jobs

```python
# Add after the /query endpoint

@app.get("/stories", response_model=ListResponse)
async def list_stories(
    limit: int = Query(DEFAULT_LIMIT, ge=1, le=MAX_LIMIT, description="Maximum items to return"),
    offset: int = Query(0, ge=0, description="Number of items to skip"),
    sort: str = Query("time", description="Sort field: time, score, descendants"),
    order: str = Query("desc", description="Sort order: asc, desc"),
    by: str | None = Query(None, description="Filter by author username"),
    min_score: int | None = Query(None, description="Minimum score filter"),
) -> ListResponse:
    """
    List stories with filtering and pagination.

    Returns story items sorted by the specified field.
    """
    # Validate sort field
    valid_sorts = {"time", "score", "descendants", "id"}
    if sort not in valid_sorts:
        raise HTTPException(status_code=400, detail=f"Invalid sort field. Must be one of: {valid_sorts}")

    # Validate order
    if order not in {"asc", "desc"}:
        raise HTTPException(status_code=400, detail="Invalid order. Must be 'asc' or 'desc'")

    # Build query
    conditions = ["type = 'story'"]
    if by:
        conditions.append(f"\"by\" = '{by}'")
    if min_score is not None:
        conditions.append(f"score >= {min_score}")

    where_clause = " AND ".join(conditions)
    sql = f"""
        SELECT id, title, url, score, "by", time::varchar as time, descendants
        FROM hn
        WHERE {where_clause}
        ORDER BY {sort} {order.upper()}
        LIMIT {limit} OFFSET {offset}
    """

    conn = _get_connection()
    start_time = time.perf_counter()
    try:
        result = conn.execute(sql)
        rows = result.fetchall()
    except duckdb.Error as e:
        raise HTTPException(status_code=400, detail=str(e))
    finally:
        conn.close()

    elapsed = time.perf_counter() - start_time

    items = [
        StoryItem(
            id=row[0],
            title=row[1],
            url=row[2],
            score=row[3],
            by=row[4],
            time=row[5],
            descendants=row[6],
        )
        for row in rows
    ]

    return ListResponse(
        items=items,
        count=len(items),
        timing=TimingInfo(
            elapsed_seconds=elapsed,
            elapsed_formatted=_format_time(elapsed),
        ),
    )


@app.get("/comments", response_model=ListResponse)
async def list_comments(
    limit: int = Query(DEFAULT_LIMIT, ge=1, le=MAX_LIMIT, description="Maximum items to return"),
    offset: int = Query(0, ge=0, description="Number of items to skip"),
    sort: str = Query("time", description="Sort field: time, id"),
    order: str = Query("desc", description="Sort order: asc, desc"),
    by: str | None = Query(None, description="Filter by author username"),
    parent: int | None = Query(None, description="Filter by parent item ID"),
) -> ListResponse:
    """
    List comments with filtering and pagination.

    Returns comment items sorted by the specified field.
    """
    valid_sorts = {"time", "id"}
    if sort not in valid_sorts:
        raise HTTPException(status_code=400, detail=f"Invalid sort field. Must be one of: {valid_sorts}")

    if order not in {"asc", "desc"}:
        raise HTTPException(status_code=400, detail="Invalid order. Must be 'asc' or 'desc'")

    conditions = ["type = 'comment'"]
    if by:
        conditions.append(f"\"by\" = '{by}'")
    if parent is not None:
        conditions.append(f"parent = {parent}")

    where_clause = " AND ".join(conditions)
    sql = f"""
        SELECT id, text, "by", time::varchar as time, parent
        FROM hn
        WHERE {where_clause}
        ORDER BY {sort} {order.upper()}
        LIMIT {limit} OFFSET {offset}
    """

    conn = _get_connection()
    start_time = time.perf_counter()
    try:
        result = conn.execute(sql)
        rows = result.fetchall()
    except duckdb.Error as e:
        raise HTTPException(status_code=400, detail=str(e))
    finally:
        conn.close()

    elapsed = time.perf_counter() - start_time

    items = [
        CommentItem(
            id=row[0],
            text=row[1],
            by=row[2],
            time=row[3],
            parent=row[4],
        )
        for row in rows
    ]

    return ListResponse(
        items=items,
        count=len(items),
        timing=TimingInfo(
            elapsed_seconds=elapsed,
            elapsed_formatted=_format_time(elapsed),
        ),
    )


@app.get("/jobs", response_model=ListResponse)
async def list_jobs(
    limit: int = Query(DEFAULT_LIMIT, ge=1, le=MAX_LIMIT, description="Maximum items to return"),
    offset: int = Query(0, ge=0, description="Number of items to skip"),
    sort: str = Query("time", description="Sort field: time, id"),
    order: str = Query("desc", description="Sort order: asc, desc"),
) -> ListResponse:
    """
    List job postings with pagination.

    Returns job items sorted by the specified field.
    """
    valid_sorts = {"time", "id"}
    if sort not in valid_sorts:
        raise HTTPException(status_code=400, detail=f"Invalid sort field. Must be one of: {valid_sorts}")

    if order not in {"asc", "desc"}:
        raise HTTPException(status_code=400, detail="Invalid order. Must be 'asc' or 'desc'")

    sql = f"""
        SELECT id, title, url, text, "by", time::varchar as time
        FROM hn
        WHERE type = 'job'
        ORDER BY {sort} {order.upper()}
        LIMIT {limit} OFFSET {offset}
    """

    conn = _get_connection()
    start_time = time.perf_counter()
    try:
        result = conn.execute(sql)
        rows = result.fetchall()
    except duckdb.Error as e:
        raise HTTPException(status_code=400, detail=str(e))
    finally:
        conn.close()

    elapsed = time.perf_counter() - start_time

    items = [
        JobItem(
            id=row[0],
            title=row[1],
            url=row[2],
            text=row[3],
            by=row[4],
            time=row[5],
        )
        for row in rows
    ]

    return ListResponse(
        items=items,
        count=len(items),
        timing=TimingInfo(
            elapsed_seconds=elapsed,
            elapsed_formatted=_format_time(elapsed),
        ),
    )
```

### Success Criteria:

#### Automated Verification:
- [x] Endpoints exist: `uv run python -c "from hn_sql.api import app; print([r.path for r in app.routes if '/stories' in r.path or '/comments' in r.path or '/jobs' in r.path])"`

#### Manual Verification:
- [ ] Start server and test: `curl "http://localhost:8000/stories?limit=5"`
- [ ] Filtering works: `curl "http://localhost:8000/stories?min_score=100&limit=5"`
- [ ] Comments endpoint works: `curl "http://localhost:8000/comments?limit=5"`
- [ ] Jobs endpoint works: `curl "http://localhost:8000/jobs?limit=5"`

**Implementation Note**: After completing this phase and all automated verification passes, pause here for manual confirmation before proceeding to the next phase.

---

## Phase 6: Implement Analytics Endpoints

### Overview
Add pre-built analytics endpoints for common queries.

### Changes Required:

#### 1. Add analytics endpoints to api.py
**File**: `src/hn_sql/api.py`
**Changes**: Add GET endpoints for /stats/types, /stats/users, /top/stories

```python
# Add after the entity endpoints

@app.get("/stats/types", response_model=StatsResponse)
async def stats_by_type() -> StatsResponse:
    """
    Get item counts grouped by type.

    Returns counts for story, comment, job, poll, and pollopt types.
    """
    sql = """
        SELECT type, count(*) as count
        FROM hn
        GROUP BY type
        ORDER BY count DESC
    """

    conn = _get_connection()
    start_time = time.perf_counter()
    try:
        result = conn.execute(sql)
        rows = result.fetchall()
    except duckdb.Error as e:
        raise HTTPException(status_code=400, detail=str(e))
    finally:
        conn.close()

    elapsed = time.perf_counter() - start_time

    stats = [TypeCount(type=row[0] or "unknown", count=row[1]) for row in rows]

    return StatsResponse(
        stats=stats,
        timing=TimingInfo(
            elapsed_seconds=elapsed,
            elapsed_formatted=_format_time(elapsed),
        ),
    )


@app.get("/stats/users", response_model=StatsResponse)
async def stats_top_users(
    limit: int = Query(100, ge=1, le=1000, description="Number of top users to return"),
) -> StatsResponse:
    """
    Get top users by post count.

    Returns users ranked by total number of posts (stories + comments).
    """
    sql = f"""
        SELECT "by" as user, count(*) as count
        FROM hn
        WHERE "by" IS NOT NULL
        GROUP BY "by"
        ORDER BY count DESC
        LIMIT {limit}
    """

    conn = _get_connection()
    start_time = time.perf_counter()
    try:
        result = conn.execute(sql)
        rows = result.fetchall()
    except duckdb.Error as e:
        raise HTTPException(status_code=400, detail=str(e))
    finally:
        conn.close()

    elapsed = time.perf_counter() - start_time

    stats = [UserCount(user=row[0], count=row[1]) for row in rows]

    return StatsResponse(
        stats=stats,
        timing=TimingInfo(
            elapsed_seconds=elapsed,
            elapsed_formatted=_format_time(elapsed),
        ),
    )


@app.get("/top/stories", response_model=ListResponse)
async def top_stories(
    limit: int = Query(100, ge=1, le=1000, description="Number of top stories to return"),
    min_score: int = Query(0, ge=0, description="Minimum score filter"),
) -> ListResponse:
    """
    Get top stories by score.

    Returns stories ranked by score (highest first).
    """
    sql = f"""
        SELECT id, title, url, score, "by", time::varchar as time, descendants
        FROM hn
        WHERE type = 'story' AND score >= {min_score}
        ORDER BY score DESC NULLS LAST
        LIMIT {limit}
    """

    conn = _get_connection()
    start_time = time.perf_counter()
    try:
        result = conn.execute(sql)
        rows = result.fetchall()
    except duckdb.Error as e:
        raise HTTPException(status_code=400, detail=str(e))
    finally:
        conn.close()

    elapsed = time.perf_counter() - start_time

    items = [
        StoryItem(
            id=row[0],
            title=row[1],
            url=row[2],
            score=row[3],
            by=row[4],
            time=row[5],
            descendants=row[6],
        )
        for row in rows
    ]

    return ListResponse(
        items=items,
        count=len(items),
        timing=TimingInfo(
            elapsed_seconds=elapsed,
            elapsed_formatted=_format_time(elapsed),
        ),
    )
```

### Success Criteria:

#### Automated Verification:
- [x] Endpoints exist: `uv run python -c "from hn_sql.api import app; print([r.path for r in app.routes if '/stats' in r.path or '/top' in r.path])"`

#### Manual Verification:
- [ ] Type stats work: `curl http://localhost:8000/stats/types`
- [ ] User stats work: `curl "http://localhost:8000/stats/users?limit=10"`
- [ ] Top stories work: `curl "http://localhost:8000/top/stories?limit=10"`

**Implementation Note**: After completing this phase and all automated verification passes, the implementation is complete.

---

## Testing Strategy

### Unit Tests:
- Query response model serialization
- Time formatting function
- SQL injection prevention in REST endpoints

### Integration Tests:
- POST /query with valid SQL returns expected structure
- POST /query with invalid SQL returns 400 error
- GET endpoints return correctly typed items
- Limit and offset work correctly

### Manual Testing Steps:
1. Start server: `uv run hn-sql api --port 8000`
2. Open docs: http://localhost:8000/docs
3. Test SQL query: `curl -X POST http://localhost:8000/query -H "Content-Type: application/json" -d '{"sql": "SELECT count(*) FROM hn"}'`
4. Test stories: `curl "http://localhost:8000/stories?limit=5&sort=score"`
5. Test filtering: `curl "http://localhost:8000/stories?by=pg&limit=5"`
6. Test analytics: `curl http://localhost:8000/stats/types`
7. Verify timing info is present in all responses

## Performance Considerations

- **Connection per request**: Each request creates a new DuckDB connection; this is lightweight as it's in-memory
- **Row limits**: Default 1,000 rows prevents accidental large responses
- **No caching**: Results are computed fresh each time; consider adding caching if needed
- **Parquet scanning**: DuckDB efficiently scans only needed partitions when filtering by year/month

## Security Considerations

- **SQL injection in POST /query**: Users can execute arbitrary SQL; this is intentional for flexibility
- **SQL injection in REST endpoints**: Query parameters are properly parameterized via f-strings with validated inputs
- **No authentication**: Assumes local/trusted network use
- **Bind to localhost by default**: Server binds to 127.0.0.1 by default, requiring explicit --host 0.0.0.0 for external access

## References

- Current CLI implementation: `src/hn_sql/cli.py`
- FastAPI documentation: https://fastapi.tiangolo.com/
- DuckDB Python API: https://duckdb.org/docs/api/python/overview
